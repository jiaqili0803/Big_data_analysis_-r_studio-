---
title: "Individual Final Submission"
author: "Ella Li (jiaqi li)"
date: "4/23/2022"
output:
  html_document:
    toc: true
    theme: readable
    highlight: tango
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 1. Load and clean data

```{r}
# read data, string variables to factors
tele <- read.csv("tele.csv", stringsAsFactors = TRUE)
# summary(tele)
# str(tele)

# drop useless columns
tele$X <- NULL
tele$duration <- NULL # We only should be using variables that we know before the call

tele$pdaysdummy <- ifelse(tele$pdays == 999, 0, 1) # Changing pdays to a dummy and deleting pdays, 999 means client was not previously contacted
tele$pdays <- NULL

# convert factors to dummy variables (input into ANN has to be numeric)
telemm <- as.data.frame(model.matrix(~.-1, tele))
# telemm
table(telemm$yyes)

# Randomize (done already)



# do Normalization
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

tele_norm <- as.data.frame(lapply(telemm, normalize))

# data structure
str(tele_norm)


```
```{r}
# check how many customer buy the service in the data set, 1 is for yes;
table(tele_norm$yyes)
```


# 2. Control model running time, so kill some columns and Randomize the dataset.
```{r}
set.seed(12345) # keep same seed everytime
kill_rows <- sample(1:nrow(tele_norm), 0.25*nrow(tele_norm)) # this will only keep the 25% of the data set and randomize them, because of the computing power;
tele_small <- tele_norm[kill_rows, ]

str(tele_small)
summary(tele_small)
# tele_small is now a small but clean data set for futher analyse
```

# 3. Train Test split
```{r}
set.seed(12345)

# split the test and train data set in 0.2:0.8 ratio;
test_set <- sample(1:nrow(tele_small), 0.2*nrow(tele_small))  
tele_train <- tele_small[-test_set, ]
tele_test <- tele_small[test_set, ]

# upsample to balance the sample size for 0 and 1 values for yyes for train data
# set.seed(12345)
# library(groupdata2)
# tele_train <- upsample(tele_train, cat_col = "yyes")
# table(tele_train$yyes)

str(tele_train)
summary(tele_train)
# str(tele_test)
# summary(tele_test)
# table(tele_train$yyes)

```


# 4. Check na
```{r}
# check whether there is any NA value
table(is.na(tele_small)) 
```


# 5. Two first level predictive models

##  5.1 Logistic Regression model
```{r}
# set up and train a logistic regression model by train data
log_model <- glm(yyes ~., data = tele_train, family = "binomial")
# use the model to do prediction on our test data
log_pred <- predict(log_model, tele_test, type="response")
# get binary results by the condition whether the prediction results  >= 0.5, if yes, will be 1, if not will be 0
log_pred_binary <- ifelse(log_pred >= 0.5, 1, 0)

# confusionMatrix for model
library(caret)
confusionMatrix(as.factor(log_pred_binary), as.factor(tele_test$yyes), positive = "1")

```
We get a result: Accuracy : 0.9038;


##  5.2 KNN model
```{r}
# label and data split for KNN, column 53 is our label/target column "yyes"
KNN_train_label <- tele_train[ , 53]
KNN_train <- tele_train[ , -53]

KNN_test_label <- tele_test[ , 53]
KNN_test <- tele_test[ , -53]

# model
library(class)
# build,train and predict using KNN model with k = 30
knn_pred <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 30) # the optimal k having best accuracy
summary(knn_pred)

# evaluation
library(caret)
# confusionMatrix result
confusionMatrix(as.factor(knn_pred), as.factor(KNN_test_label), positive = "1")
```
This model's accuracy : 0.8975
<!-- ##  5.3 ANN model -->
<!-- ```{r} -->
<!-- library(neuralnet) -->

<!-- ann_model <- neuralnet(yyes ~., data = tele_train) -->
<!-- plot(ann_model) -->
<!-- ann_pred <- predict(ann_model, tele_test, type="response") -->
<!-- ann_pred_binary <- ifelse(ann_pred >= 0.5, 1, 0) -->

<!-- confusionMatrix(as.factor(ann_pred_binary), as.factor(tele_test$yyes), positive = "1") -->

<!-- # we need non-binary values for stack model for ANN and logi -->
<!-- ``` -->

<!-- ##  5.4 Decision Tree model -->
<!-- ```{r} -->
<!-- library(C50) -->
<!-- DT_model <- C5.0(as.factor(yyes) ~., data = tele_train) # C5.0 models require a factor outcome -->
<!-- # plot(DT_model) -->
<!-- # summary(DT_model) -->

<!-- DT_pred <- predict(DT_model, tele_test) -->

<!-- confusionMatrix(as.factor(DT_pred), as.factor(tele_test$yyes), positive = "1") -->

<!-- ``` -->

<!-- ##  5.5 Random forest model -->
<!-- ```{r} -->
<!-- library(randomForest) -->

<!-- rf_model <- randomForest(as.factor(yyes) ~., data = tele_train) -->
<!-- plot(rf_model) -->
<!-- rf_pred <- predict(rf_model, tele_test) -->

<!-- confusionMatrix(as.factor(rf_pred), as.factor(tele_test$yyes), positive = "1") -->

<!-- # find patterns -->
<!-- randomForest::importance(rf_model) -->
<!-- randomForest::varImpPlot(rf_model) -->

<!-- ``` -->

<!-- # 6. Improve models -->

<!-- ## 6.1 Try different K for KNN -->
<!-- ```{r} -->
<!-- # when k=40, Accuracy=0.91 -->
<!-- knn_pred_1 <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 37)  -->
<!-- #knn_pred_2 <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 58)  -->

<!-- confusionMatrix(as.factor(knn_pred_1), as.factor(KNN_test_label), positive = "1") -->
<!-- #confusionMatrix(as.factor(knn_pred_2), as.factor(KNN_test_label), positive = "1") -->
<!-- ``` -->

<!-- ## 6.2 Use the Caret Train function to auto tune Decision Tree and pick the best -->
<!-- ```{r} -->
<!-- # automated parameter tuning of C5.0 decision tree -->
<!-- DT_tune_model <- train(as.factor(yyes) ~., data = tele_train, method = "C5.0") -->
<!-- DT_tune_model -->

<!-- # apply the best C5.0 candidate model to make predictions -->
<!-- DT_tune_pred <- predict(DT_tune_model, tele_test) -->
<!-- confusionMatrix(as.factor(DT_tune_pred), as.factor(tele_test$yyes), positive = "1") -->

<!-- ``` -->

<!-- ## 6.3 Use the Caret Train function for auto-tune a boosted customized C5.0 Decision Tree -->
<!-- ```{r} -->
<!-- # customized -->
<!-- grid_c50 <- expand.grid(.model = "tree", -->
<!--                         .trials = c(10, 20, 30, 40, 50), -->
<!--                         .winnow = "FALSE") -->

<!-- ctrl <- trainControl(method = "cv", number = 10, -->
<!--                      selectionFunction = "oneSE") -->

<!-- # auto-tune model -->
<!-- DT_tune_model_customized <- train(as.factor(yyes) ~., data = tele_train, method = "C5.0", -->
<!--                 metric = "Kappa", trControl = ctrl, -->
<!--                tuneGrid = grid_c50) -->

<!-- DT_tune_customized_pred <- predict(DT_tune_model_customized, tele_test) -->

<!-- # evaluation -->
<!-- confusionMatrix(as.factor(DT_tune_customized_pred), as.factor(tele_test$yyes), positive = "1") -->

<!-- ``` -->

# 6. Stacked Model
```{r}
# build a stack/second level model using the previous logistic regression and KNN model, compared to the test true label value
stack_model <- data.frame(log_pred, knn_pred, tele_test$yyes)
# rename the column
colnames(stack_model) <- c("logi_reg", "KNN", "True_yyes")

summary(stack_model)
str(stack_model)
  
```


# 7. Break stack model data frame into test and train, and do decision tree
```{r}
set.seed(12345)
# split the test and train data for the stack model using ratio 0.2:0.8
test_set <- sample(1:nrow(stack_model), 0.2*nrow(stack_model)) 

stack_model_train <- stack_model[-test_set, ]
stack_model_test <- stack_model[test_set, ]

str(stack_model_train)

# using decision tree model to do prediction and get results
library(C50)
stack_model_DT <- C5.0(as.factor(True_yyes)~., stack_model_train)

stack_model_pred <- predict(stack_model_DT, stack_model_test)

# Build a Confusion Matrix
confusionMatrix(stack_model_pred, as.factor(stack_model_test$True_yyes), positive = "1")


```
This stack model have Accuracy : 0.8954;

```{r}
library(gmodels)
# build a CrossTable to easily calculate the profit
CrossTable(stack_model_pred, as.factor(stack_model_test$True_yyes), prop.chisq = F,prop.r = F, prop.c = F, prop.t = F)
```
From CrossTable, we can easily find that total data in prediction is 411, and 365 people did not buy the service, only 46 people had buy the service;
Using the stack model we built, the people predicted as "1" i.e. will buy the service is counted as 13, and 5 of them actually did not buy the service, 8 of them did buy the service.

# 8. Conclusion

We assume that it costs 1 dollar to make each call and every successful call results in a net profit of $8.
I built a predictive stack model such that the Call Center will ONLY call those customers that the model classify as likely to be successful. i.e. "1" in the confusionMatrix;
My model Accuracy is 0.8954;

If we do not follow the model, we will get 46*8-411=(-43) dollars lost;
If we follow the model, we will have 8*8-13=(+51) dollars net profit;
So, the call center can save a lot of money and maximize their net profit (i.e total profit from successful calls minus total cost of unsuccessful calls);

If call center make 10,000 calls recommended by my model, A very rough projection based on the current results shows that 13 calls made according to my model can save the call center (51+43)=94 dollars. 
So, 10,000 calls would save (94/13*10000) = 72307 dollars;
The net profit would reach (51/13*10000) = 39230 dollars.

So, the model is useful for the call center management decision!