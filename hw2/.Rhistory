test_set <- sample(1:nrow(tele_norm), 400)
# Depending on R-version and computer, different rows may be selected.
# If that happens, results are different.
# Create a train set and test set
#First the predictors - all columns except the yyes column
tele_train <- tele_norm[-test_set, ]
tele_test <- tele_norm[test_set, ]
str(tele_train)
summary(tele_train)
str(tele_test)
summary(tele_test)
table(is.na(tele_train))
#Downloading and Prepping the Data
tele <- read.csv("tele.csv", stringsAsFactors = TRUE)
summary(tele)
#We are deleting the "duration" variable because it is an after the fact measurement. We only should be using variables that we know before the call
tele$duration <- NULL
# Deleting the columns X
tele$X <- NULL
# only for class exercise!
# tele$day_of_week <- NULL
# tele$month <- NULL
# tele$job <- NULL
# tele$education <- NULL
tele$default <- NULL
# Changing pdays to a dummy and deleting pdays
tele$pdaysdummy <- ifelse(tele$pdays == 999, 0, 1)
tele$pdays <- NULL
tele <- na.omit(tele)
set.seed(12345)
kill_rows <- sample(1:nrow(tele), 0.05*nrow(tele))
tele <- tele[kill_rows, ]
str(tele)
# Using model.matrix to convert all the factors to dummy variables
# We are converting all of the factors into dummy variables as the input into ANN has to be numeric
telemm <- as.data.frame(model.matrix(~.-1,tele))
table(telemm$yyes)
# Randomize the rows in the data (shuffling the rows)
set.seed(12345)
# tele_random <- telemm[sample(nrow(telemm)),]
# do upsample to balance the sample size for 0 and 1 values for yyes
library(groupdata2)
tele_random <- upsample(telemm, cat_col = "yyes")
table(tele_random$yyes)
#Normalize the data
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
# we are going to normalize everything
# we use telemm here because  we did not randomize
tele_norm <- as.data.frame(lapply(tele_random, normalize))
str(tele_norm)
# Selects 10000 random rows for test data
set.seed(12345)
# choose 2000 only for class exercise, or 10000
test_set <- sample(1:nrow(tele_norm), 400)
# Depending on R-version and computer, different rows may be selected.
# If that happens, results are different.
# Create a train set and test set
#First the predictors - all columns except the yyes column
tele_train <- tele_norm[-test_set, ]
tele_test <- tele_norm[test_set, ]
str(tele_train)
summary(tele_train)
str(tele_test)
summary(tele_test)
table(is.na(tele_train))
table(is.na(tele_norm))
library(neuralnet)
model_1 <- neuralnet(yyes ~., data=tele_train, stepmax = 1e5, )
# Using model.matrix to convert all the factors to dummy variables
# We are converting all of the factors into dummy variables as the input into ANN has to be numeric
telemm <- as.data.frame(model.matrix(~.-1,tele))
table(telemm$yyes)
# Randomize the rows in the data (shuffling the rows)
set.seed(12345)
# tele_random <- telemm[sample(nrow(telemm)),]
# do upsample to balance the sample size for 0 and 1 values for yyes
library(groupdata2)
tele_random <- upsample(telemm, cat_col = "yyes")
table(tele_random$yyes)
tele_random <- na.omit(tele_random)
table(tele_random$yyes)
#Normalize the data
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
# we are going to normalize everything
# we use telemm here because  we did not randomize
tele_norm <- as.data.frame(lapply(tele_random, normalize))
str(tele_norm)
# Using model.matrix to convert all the factors to dummy variables
# We are converting all of the factors into dummy variables as the input into ANN has to be numeric
telemm <- as.data.frame(model.matrix(~.-1,tele))
table(telemm$yyes)
# Randomize the rows in the data (shuffling the rows)
set.seed(12345)
# tele_random <- telemm[sample(nrow(telemm)),]
# do upsample to balance the sample size for 0 and 1 values for yyes
library(groupdata2)
tele_random <- upsample(telemm, cat_col = "yyes")
table(tele_random$yyes)
tele_random <- na.omit(tele_random)
table(tele_random$yyes)
#Normalize the data
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
# we are going to normalize everything
# we use telemm here because  we did not randomize
tele_norm <- as.data.frame(lapply(tele_random, normalize))
str(tele_norm)
#Downloading and Prepping the Data
tele <- read.csv("tele.csv", stringsAsFactors = TRUE)
summary(tele)
#We are deleting the "duration" variable because it is an after the fact measurement. We only should be using variables that we know before the call
tele$duration <- NULL
# Deleting the columns X
tele$X <- NULL
# only for class exercise!
# tele$day_of_week <- NULL
# tele$month <- NULL
# tele$job <- NULL
# tele$education <- NULL
tele$default <- NULL
# Changing pdays to a dummy and deleting pdays
tele$pdaysdummy <- ifelse(tele$pdays == 999, 0, 1)
tele$pdays <- NULL
set.seed(12345)
kill_rows <- sample(1:nrow(tele), 0.05*nrow(tele))
tele <- tele[kill_rows, ]
str(tele)
# Using model.matrix to convert all the factors to dummy variables
# We are converting all of the factors into dummy variables as the input into ANN has to be numeric
telemm <- as.data.frame(model.matrix(~.-1,tele))
table(telemm$yyes)
# Randomize the rows in the data (shuffling the rows)
set.seed(12345)
# tele_random <- telemm[sample(nrow(telemm)),]
# do upsample to balance the sample size for 0 and 1 values for yyes
library(groupdata2)
tele_random <- upsample(telemm, cat_col = "yyes")
table(tele_random$yyes)
tele_random <- na.omit(tele_random)
table(tele_random$yyes)
#Normalize the data
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
# we are going to normalize everything
# we use telemm here because  we did not randomize
tele_norm <- as.data.frame(lapply(tele_random, normalize))
str(tele_norm)
# Selects 10000 random rows for test data
set.seed(12345)
# choose 2000 only for class exercise, or 10000
test_set <- sample(1:nrow(tele_norm), 400)
# Depending on R-version and computer, different rows may be selected.
# If that happens, results are different.
# Create a train set and test set
#First the predictors - all columns except the yyes column
tele_train <- tele_norm[-test_set, ]
tele_test <- tele_norm[test_set, ]
str(tele_train)
summary(tele_train)
str(tele_test)
summary(tele_test)
table(is.na(tele_norm))
table(is.na(tele_norm))
library(neuralnet)
model_1 <- neuralnet(yyes ~., data=tele_train, stepmax = 1e5, )
library(neuralnet)
model_1 <- neuralnet(yyes ~., data=tele_train, stepmax = 1e5, na.rm = TRUE)
# Selects 10000 random rows for test data
set.seed(12345)
# choose 2000 only for class exercise, or 10000
test_set <- sample(1:nrow(tele_norm), 400)
# Depending on R-version and computer, different rows may be selected.
# If that happens, results are different.
# Create a train set and test set
#First the predictors - all columns except the yyes column
tele_train <- tele_norm[-test_set, ]
tele_test <- tele_norm[test_set, ]
str(tele_train)
summary(tele_train)
# str(tele_test)
# summary(tele_test)
# Selects 10000 random rows for test data
set.seed(12345)
# choose 2000 only for class exercise, or 10000
test_set <- sample(1:nrow(tele_norm), 400)
str(test_set)
# Depending on R-version and computer, different rows may be selected.
# If that happens, results are different.
# Create a train set and test set
#First the predictors - all columns except the yyes column
tele_train <- tele_norm[-test_set, ]
tele_test <- tele_norm[test_set, ]
str(tele_train)
summary(tele_train)
# str(tele_test)
# summary(tele_test)
# Selects 10000 random rows for test data
set.seed(12345)
# choose 2000 only for class exercise, or 10000
test_set <- sample(1:nrow(tele_norm), 400)
str(test_set)
# Depending on R-version and computer, different rows may be selected.
# If that happens, results are different.
# Create a train set and test set
#First the predictors - all columns except the yyes column
tele_train <- tele_norm[-test_set, ]
tele_test <- tele_norm[test_set, ]
# str(tele_train)
# summary(tele_train)
# str(tele_test)
# summary(tele_test)
# Selects 10000 random rows for test data
set.seed(12345)
# choose 2000 only for class exercise, or 10000
test_set <- sample(1:nrow(tele_norm), 400)
# Depending on R-version and computer, different rows may be selected.
# If that happens, results are different.
# Create a train set and test set
#First the predictors - all columns except the yyes column
tele_train <- tele_norm[-test_set, ]
tele_test <- tele_norm[test_set, ]
str(tele_train)
# summary(tele_train)
# str(tele_test)
# summary(tele_test)
table(is.na(tele_train))
library(neuralnet)
model_1 <- neuralnet(yyes ~., data=tele_train, stepmax = 1e5, na.rm = TRUE)
library(neuralnet)
model_1 <- neuralnet(yyes ~., data=tele_train, stepmax = 1e5)
# Selects 10000 random rows for test data
set.seed(12345)
# choose 2000 only for class exercise, or 10000
test_set <- sample(1:nrow(tele_norm), 400)
# Depending on R-version and computer, different rows may be selected.
# If that happens, results are different.
# Create a train set and test set
#First the predictors - all columns except the yyes column
tele_train <- tele_norm[-test_set, ]
tele_test <- tele_norm[test_set, ]
str(tele_train)
summary(tele_train)
# str(tele_test)
# summary(tele_test)
# Selects 10000 random rows for test data
set.seed(12345)
# dropeducationilliterate because of NA after norm
tele_norm$educationilliterate <- NULL
# choose 2000 only for class exercise, or 10000
test_set <- sample(1:nrow(tele_norm), 400)
# Depending on R-version and computer, different rows may be selected.
# If that happens, results are different.
# Create a train set and test set
#First the predictors - all columns except the yyes column
tele_train <- tele_norm[-test_set, ]
tele_test <- tele_norm[test_set, ]
str(tele_train)
summary(tele_train)
# str(tele_test)
# summary(tele_test)
table(is.na(tele_train))
library(neuralnet)
model_1 <- neuralnet(yyes ~., data=tele_train, stepmax = 1e5)
plot(model_1)
#Downloading and Prepping the Data
tele <- read.csv("tele.csv", stringsAsFactors = TRUE)
summary(tele)
#We are deleting the "duration" variable because it is an after the fact measurement. We only should be using variables that we know before the call
tele$duration <- NULL
# Deleting the columns X
tele$X <- NULL
# only for class exercise!
# tele$day_of_week <- NULL
# tele$month <- NULL
# tele$job <- NULL
# tele$education <- NULL
tele$default <- NULL
# Changing pdays to a dummy and deleting pdays
tele$pdaysdummy <- ifelse(tele$pdays == 999, 0, 1)
tele$pdays <- NULL
set.seed(12345)
kill_rows <- sample(1:nrow(tele), 0.05*nrow(tele))
tele <- tele[kill_rows, ]
str(tele)
# Using model.matrix to convert all the factors to dummy variables
# We are converting all of the factors into dummy variables as the input into ANN has to be numeric
telemm <- as.data.frame(model.matrix(~.-1,tele))
table(telemm$yyes)
# Randomize the rows in the data (shuffling the rows)
set.seed(12345)
# tele_random <- telemm[sample(nrow(telemm)),]
# do upsample to balance the sample size for 0 and 1 values for yyes
library(groupdata2)
tele_random <- upsample(telemm, cat_col = "yyes")
table(tele_random$yyes)
tele_random <- na.omit(tele_random)
table(tele_random$yyes)
#Normalize the data
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
# we are going to normalize everything
# we use telemm here because  we did not randomize
tele_norm <- as.data.frame(lapply(tele_random, normalize))
str(tele_norm)
# Selects 10000 random rows for test data
set.seed(12345)
# dropeducationilliterate because of NA after norm
tele_norm$educationilliterate <- NULL
# choose 2000 only for class exercise, or 10000
test_set <- sample(1:nrow(tele_norm), 400)
# Depending on R-version and computer, different rows may be selected.
# If that happens, results are different.
# Create a train set and test set
#First the predictors - all columns except the yyes column
tele_train <- tele_norm[-test_set, ]
tele_test <- tele_norm[test_set, ]
str(tele_train)
summary(tele_train)
# str(tele_test)
# summary(tele_test)
table(is.na(tele_train))
library(neuralnet)
model_1 <- neuralnet(yyes ~., data=tele_train, stepmax = 1e5)
plot(model_1)
library(neuralnet)
model_1 <- neuralnet(yyes ~., data=tele_train, stepmax = 1e8)
plot(model_1)
p1 <- predict(model_1, tele_test) # predict only use the x data from test set, to predict y
summary(p1)
p1_binary <- ifelse(p1 >= 0.5, 1, 0)
library(gmodels)
CrossTable(p1_binary, tele_test$yyes, prop.chisq = F,prop.r = F, prop.c = F, prop.t = F)
# compare y and true y
library(gmodels)
CrossTable(p1_binary, tele_test$yyes, prop.chisq = F,prop.r = F, prop.c = F, prop.t = F)
# compare y and true y
library(caret)
#Confusion Matrix
confusionMatrix(as.factor(tele_test$yyes), as.factor(p1_binary), positive = "1")
model_2 <- neuralnet(yyes ~., data=tele_train, hidden=5, stepmax = 1e8)
plot(model_2)
p2 <- predict(model_2, tele_test) # predict only use the x data from test set, to predict y
summary(p2)
p2_binary <- ifelse(p2 >= 0.5, 1, 0)
CrossTable(p2_binary, tele_test$yyes, prop.chisq = F,prop.r = F, prop.c = F, prop.t = F)
confusionMatrix(as.factor(tele_test$yyes), as.factor(p2_binary), positive = "1")
model_3 <- neuralnet(yyes ~., data=tele_train, hidden = c(4,3,2), stepmax = 1e8)
CrossTable(p3_binary, tele_test$yyes, prop.chisq = F,prop.r = F, prop.c = F, prop.t = F)
knitr::opts_chunk$set(echo = TRUE)
#Downloading and Prepping the Data
tele <- read.csv("tele.csv", stringsAsFactors = TRUE)
summary(tele)
#We are deleting the "duration" variable because it is an after the fact measurement. We only should be using variables that we know before the call
tele$duration <- NULL
# Deleting the columns X
tele$X <- NULL
# only for class exercise!
# tele$day_of_week <- NULL
# tele$month <- NULL
# tele$job <- NULL
# tele$education <- NULL
tele$default <- NULL
# Changing pdays to a dummy and deleting pdays
tele$pdaysdummy <- ifelse(tele$pdays == 999, 0, 1)
tele$pdays <- NULL
set.seed(12345)
kill_rows <- sample(1:nrow(tele), 0.05*nrow(tele))
tele <- tele[kill_rows, ]
str(tele)
# Using model.matrix to convert all the factors to dummy variables
# We are converting all of the factors into dummy variables as the input into ANN has to be numeric
telemm <- as.data.frame(model.matrix(~.-1,tele))
table(telemm$yyes)
# Randomize the rows in the data (shuffling the rows)
set.seed(12345)
# tele_random <- telemm[sample(nrow(telemm)),]
# do upsample to balance the sample size for 0 and 1 values for yyes
library(groupdata2)
tele_random <- upsample(telemm, cat_col = "yyes")
table(tele_random$yyes)
tele_random <- na.omit(tele_random)
table(tele_random$yyes)
#Normalize the data
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
# we are going to normalize everything
# we use telemm here because  we did not randomize
tele_norm <- as.data.frame(lapply(tele_random, normalize))
str(tele_norm)
# Selects 10000 random rows for test data
set.seed(12345)
# dropeducationilliterate because of NA after norm
tele_norm$educationilliterate <- NULL
# choose 2000 only for class exercise, or 10000
test_set <- sample(1:nrow(tele_norm), 400)
# Depending on R-version and computer, different rows may be selected.
# If that happens, results are different.
# Create a train set and test set
#First the predictors - all columns except the yyes column
tele_train <- tele_norm[-test_set, ]
tele_test <- tele_norm[test_set, ]
str(tele_train)
summary(tele_train)
# str(tele_test)
# summary(tele_test)
table(is.na(tele_train))
library(neuralnet)
model_1 <- neuralnet(yyes ~., data=tele_train, stepmax = 1e8)
plot(model_1)
model_2 <- neuralnet(yyes ~., data=tele_train, hidden=5, stepmax = 1e8)
plot(model_2)
# model_3 <- neuralnet(yyes ~., data=tele_train, hidden = c(4,3,2), stepmax = 1e8)
#
# plot(model_3)
p1 <- predict(model_1, tele_test) # predict only use the x data from test set, to predict y
summary(p1)
p1_binary <- ifelse(p1 >= 0.5, 1, 0)
p2 <- predict(model_2, tele_test) # predict only use the x data from test set, to predict y
summary(p2)
p2_binary <- ifelse(p2 >= 0.5, 1, 0)
# p3 <- predict(model_3, tele_test) # predict only use the x data from test set, to predict y
# summary(p3)
#
# p3_binary <- ifelse(p3 >= 0.5, 1, 0)
library(gmodels)
CrossTable(p1_binary, tele_test$yyes, prop.chisq = F,prop.r = F, prop.c = F, prop.t = F)
# compare y and true y
library(caret)
#Confusion Matrix
confusionMatrix(as.factor(tele_test$yyes), as.factor(p1_binary), positive = "1")
CrossTable(p2_binary, tele_test$yyes, prop.chisq = F,prop.r = F, prop.c = F, prop.t = F)
confusionMatrix(as.factor(tele_test$yyes), as.factor(p2_binary), positive = "1")
# CrossTable(p3_binary, tele_test$yyes, prop.chisq = F,prop.r = F, prop.c = F, prop.t = F)
# confusionMatrix(as.factor(tele_test$yyes), as.factor(p3_binary), positive = "1")
knitr::opts_chunk$set(echo = TRUE)
TelcoChurn <- read.csv("TelcoChurn.csv", stringsAsFactors =  TRUE)
TelcoChurn$customerID <- NULL
str(TelcoChurn)
summary(TelcoChurn)
TelcoChurn_MM <- as.data.frame(model.matrix(~. -1, TelcoChurn))
str(TelcoChurn)
#Normalize the data
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
TelcoChurn_norm <- as.data.frame(lapply(TelcoChurn_MM, normalize))
set.seed(12345)
TelcoChurn_random <- TelcoChurn_norm[sample(nrow(TelcoChurn_norm)),]
log_model <- glm(ChurnYes ~., data=TelcoChurn_random, family = "binomial")
TelcoChurn_log_pred <- predict(log_model, TelcoChurn_random, type="response")
TelcoChurn_log_pred_binary <- ifelse(TelcoChurn_log_pred >= 0.5, 1, 0)
library(caret)
confusionMatrix(as.factor(TelcoChurn_log_pred_binary), as.factor(TelcoChurn_random$ChurnYes))
TelcoChurn_label_KNN <- TelcoChurn_random[, 32]
library(class)
TelcoChurn_pred_KNN <- knn(train = TelcoChurn_random[, 32], test = TelcoChurn_random[, 32], cl=TelcoChurn_label_KNN, k=83)
TelcoChurn_label_KNN <- TelcoChurn_random[, 32]
library(class)
TelcoChurn_pred_KNN <- knn(train = TelcoChurn_random[, 32], test=TelcoChurn_random[, 32], cl=TelcoChurn_label_KNN, k=83)
TelcoChurn_label_KNN <- TelcoChurn_random[, 32]
library(class)
TelcoChurn_pred_KNN <- knn(train = TelcoChurn_random[, 32], test=TelcoChurn_random[, 32], cl=TelcoChurn_label_KNN, k=83)
TelcoChurn_label_KNN <- TelcoChurn_random[, 32]
library(class)
TelcoChurn_pred_KNN <- knn(train = TelcoChurn_random[, -32], test=TelcoChurn_random[, -32], cl=TelcoChurn_label_KNN, k=83)
library(caret)
confusionMatrix(as.factor(TelcoChurn_pred_KNN), as.factor(TelcoChurn_label_KNN), positive = "1")
library(neuralnet)
ANN_model <- neuralnet(ChurnYes ~., data=TelcoChurn_random)
TelcoChurn_pred_ANN <- predict(ANN_model, TelcoChurn_random, type="response")
TelcoChurn_pred_ANN_binary <- ifelse(TelcoChurn_pred_ANN >= 0.5, 1, 0)
confusionMatrix(as.factor(TelcoChurn_pred_ANN_binary), as.factor(TelcoChurn_random$ChurnYes))
# we need non-binary values for stack model for ANN and logi
library(C50)
DT_model <- C5.0(as.factor(ChurnYes) ~., data= TelcoChurn_random)
TelcoChurn_pred_DT <- predict(DT_model, TelcoChurn_random)
confusionMatrix(as.factor(TelcoChurn_pred_DT), as.factor(TelcoChurn_random$ChurnYes))
stack_model <- data.frame(TelcoChurn_log_pred, TelcoChurn_pred_KNN, TelcoChurn_pred_ANN, TelcoChurn_pred_DT, TelcoChurn_random$ChurnYes)
colnames(stack_model) <- c("logi_reg", "KNN", "ANN", "DT", "True_ChurnYes")
summary(stack_model)
set.seed(12345)
test_set <- sample(1:nrow(stack_model), 0.2*nrow(stack_model))
stack_model_train <- stack_model[-test_set, ]
stack_model_test <- stack_model[test_set, ]
stack_model_DT <- C5.0(as.factor(ChurnYes)~., stack_model_train)
set.seed(12345)
test_set <- sample(1:nrow(stack_model), 0.2*nrow(stack_model))
stack_model_train <- stack_model[-test_set, ]
stack_model_test <- stack_model[test_set, ]
str(stack_model_train)
stack_model <- data.frame(TelcoChurn_log_pred, TelcoChurn_pred_KNN, TelcoChurn_pred_ANN, TelcoChurn_pred_DT, TelcoChurn_random$ChurnYes)
colnames(stack_model) <- c("logi_reg", "KNN", "ANN", "DT", "True_ChurnYes")
summary(stack_model)
str(stack_model)
set.seed(12345)
test_set <- sample(1:nrow(stack_model), 0.2*nrow(stack_model))
stack_model_train <- stack_model[-test_set, ]
stack_model_test <- stack_model[test_set, ]
str(stack_model_train)
stack_model_DT <- C5.0(as.factor(True_ChurnYes)~., stack_model_train)
stack_model_pred_test <- predict(stack_model_DT, stack_model_test)
confusionMatrix(stack_model_pred_test, as.factor(stack_model_test$ChurnYes))
stack_model_pred_test <- predict(stack_model_DT, stack_model_test)
confusionMatrix(stack_model_pred_test, as.factor(stack_model_test$True_ChurnYes))
