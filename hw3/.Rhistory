# tele_small is now a small but clean data set for futhur analyse
set.seed(12345)
test_set <- sample(1:nrow(tele_small), 0.2*nrow(tele_small))
tele_train <- tele_small[-test_set, ]
tele_test <- tele_small[test_set, ]
# upsample to balance the sample size for 0 and 1 values for yyes for train data
set.seed(12345)
library(groupdata2)
tele_train <- upsample(tele_train, cat_col = "yyes")
table(tele_train$yyes)
str(tele_train)
summary(tele_train)
# str(tele_test)
# summary(tele_test)
# table(tele_train$yyes)
set.seed(12345)
test_set <- sample(1:nrow(tele_small), 0.2*nrow(tele_small))
tele_train <- tele_small[-test_set, ]
tele_test <- tele_small[test_set, ]
# upsample to balance the sample size for 0 and 1 values for yyes for train data
set.seed(12345)
library(groupdata2)
tele_train <- upsample(tele_train, cat_col = "yyes")
table(tele_train$yyes)
str(tele_train)
summary(tele_train)
# str(tele_test)
# summary(tele_test)
# table(tele_train$yyes)
table(is.na(tele_small))
log_model <- glm(yyes ~., data = tele_train, family = "binomial")
log_pred <- predict(log_model, tele_test, type="response")
log_pred_binary <- ifelse(log_pred >= 0.5, 1, 0)
library(caret)
confusionMatrix(as.factor(log_pred_binary), as.factor(tele_test$yyes), positive = "1")
str(KNN_train)
log_model <- glm(yyes ~., data = tele_train, family = "binomial")
log_pred <- predict(log_model, tele_test, type="response")
log_pred_binary <- ifelse(log_pred >= 0.5, 1, 0)
library(caret)
confusionMatrix(as.factor(log_pred_binary), as.factor(tele_test$yyes), positive = "1")
# label and data split
KNN_train_label <- tele_train[ , 53]
KNN_train <- tele_train[ , -53]
KNN_test_label <- tele_test[ , 53]
KNN_test <- tele_test[ , -53]
# model
library(class)
knn_pred <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 77) # train data rows square root = k
summary(knn_pred)
# evaluation
library(caret)
confusionMatrix(as.factor(knn_pred), as.factor(KNN_test_label), positive = "1")
library(neuralnet)
ann_model <- neuralnet(yyes ~., data = tele_train)
plot(ann_model)
library(neuralnet)
ann_model <- neuralnet(yyes ~., data = tele_train)
tele <- read.csv("tele.csv", stringsAsFactors = TRUE)
# summary(tele)
# str(tele)
# drop useless columns
tele$X <- NULL
tele$duration <- NULL # We only should be using variables that we know before the call
tele$pdaysdummy <- ifelse(tele$pdays == 999, 0, 1) # Changing pdays to a dummy and deleting pdays, 999 means client was not previously contacted
tele$pdays <- NULL
# convert factors to dummy variables (input into ANN has to be numeric)
telemm <- as.data.frame(model.matrix(~.-1, tele))
# telemm
table(telemm$yyes)
# Randomize (done already)
# Normalization
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
tele_norm <- as.data.frame(lapply(telemm, normalize))
str(tele_norm)
set.seed(12345)
kill_rows <- sample(1:nrow(tele_norm), 0.05*nrow(tele_norm))
tele_small <- tele_norm[kill_rows, ]
str(tele_small)
summary(tele_small)
# tele_small is now a small but clean data set for futher analyse
set.seed(12345)
test_set <- sample(1:nrow(tele_small), 0.2*nrow(tele_small))
tele_train <- tele_small[-test_set, ]
tele_test <- tele_small[test_set, ]
# upsample to balance the sample size for 0 and 1 values for yyes for train data
set.seed(12345)
library(groupdata2)
tele_train <- upsample(tele_train, cat_col = "yyes")
table(tele_train$yyes)
str(tele_train)
summary(tele_train)
# str(tele_test)
# summary(tele_test)
# table(tele_train$yyes)
table(is.na(tele_small))
log_model <- glm(yyes ~., data = tele_train, family = "binomial")
log_pred <- predict(log_model, tele_test, type="response")
log_pred_binary <- ifelse(log_pred >= 0.5, 1, 0)
library(caret)
confusionMatrix(as.factor(log_pred_binary), as.factor(tele_test$yyes), positive = "1")
# label and data split
KNN_train_label <- tele_train[ , 53]
KNN_train <- tele_train[ , -53]
KNN_test_label <- tele_test[ , 53]
KNN_test <- tele_test[ , -53]
# model
library(class)
knn_pred <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 54) # train data rows square root = k
summary(knn_pred)
# evaluation
library(caret)
confusionMatrix(as.factor(knn_pred), as.factor(KNN_test_label), positive = "1")
library(neuralnet)
ann_model <- neuralnet(yyes ~., data = tele_train)
plot(ann_model)
ann_pred <- predict(ann_model, tele_test, type="response")
ann_pred_binary <- ifelse(ann_pred >= 0.5, 1, 0)
confusionMatrix(as.factor(ann_pred_binary), as.factor(tele_test$yyes), positive = "1")
# we need non-binary values for stack model for ANN and logi
library(C50)
DT_model <- C5.0(as.factor(yyes) ~., data = tele_train) # C5.0 models require a factor outcome
# plot(DT_model)
# summary(DT_model)
DT_pred <- predict(DT_model, tele_test)
confusionMatrix(as.factor(DT_pred), as.factor(tele_test$yyes), positive = "1")
library(randomForest)
rf_model <- randomForest(as.factor(yyes) ~., data = tele_train)
plot(rf_model)
rf_pred <- predict(rf_model, tele_test)
confusionMatrix(as.factor(rf_pred), as.factor(tele_test$yyes), positive = "1")
# find patterns
randomForest::importance(rf_model)
randomForest::varImpPlot(rf_model)
# when k=54, Accuracy=0.708
knn_pred_1 <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 55)
#knn_pred_2 <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 58)
confusionMatrix(as.factor(knn_pred_1), as.factor(KNN_test_label), positive = "1")
#confusionMatrix(as.factor(knn_pred_2), as.factor(KNN_test_label), positive = "1")
# automated parameter tuning of C5.0 decision tree
DT_tune_model <- train(as.factor(yyes) ~., data = tele_train, method = "C5.0")
DT_tune_model
# apply the best C5.0 candidate model to make predictions
DT_tune_pred <- predict(DT_tune_model, tele_test)
confusionMatrix(as.factor(DT_tune_pred), as.factor(tele_test$yyes), positive = "1")
# customized
grid_c50 <- expand.grid(.model = "tree",
.trials = c(10, 20, 30, 40),
.winnow = "FALSE")
ctrl <- trainControl(method = "cv", number = 10,
selectionFunction = "oneSE")
# auto-tune model
DT_tune_model_customized <- train(as.factor(yyes) ~., data = tele_train, method = "C5.0",
metric = "Kappa", trControl = ctrl,
tuneGrid = grid_c50)
DT_tune_customized_pred <- predict(DT_tune_model_customized, tele_test)
# evaluation
confusionMatrix(as.factor(DT_tune_customized_pred), as.factor(tele_test$yyes), positive = "1")
stack_model <- data.frame(log_pred, knn_pred_1, ann_pred, DT_tune_pred, rf_pred, tele_test$yyes)
colnames(stack_model) <- c("logi_reg", "tuned_KNN", "ANN", "tuned_DT", "Random Forest", "True_yyes")
summary(stack_model)
str(stack_model)
set.seed(12345)
test_set <- sample(1:nrow(stack_model), 0.25*nrow(stack_model))
stack_model_train <- stack_model[-test_set, ]
stack_model_test <- stack_model[test_set, ]
str(stack_model_train)
# model
stack_model_DT <- C5.0(as.factor(True_yyes)~., stack_model_train)
stack_model_pred <- predict(stack_model_DT, stack_model_test)
confusionMatrix(stack_model_pred, as.factor(stack_model_test$True_yyes), positive = "1")
library(gmodels)
CrossTable(stack_model_pred, as.factor(stack_model_test$True_yyes), positive = "1", prop.chisq = F,prop.r = F, prop.c = F, prop.t = F)
library(gmodels)
CrossTable(stack_model_pred, as.factor(stack_model_test$True_yyes), positive = "1", prop.chisq = F,prop.r = F, prop.c = F, prop.t = F)
set.seed(12345)
test_set <- sample(1:nrow(stack_model), 0.3*nrow(stack_model))
stack_model_train <- stack_model[-test_set, ]
stack_model_test <- stack_model[test_set, ]
str(stack_model_train)
# model
stack_model_DT <- C5.0(as.factor(True_yyes)~., stack_model_train)
stack_model_pred <- predict(stack_model_DT, stack_model_test)
confusionMatrix(stack_model_pred, as.factor(stack_model_test$True_yyes), positive = "1")
library(gmodels)
CrossTable(stack_model_pred, as.factor(stack_model_test$True_yyes), positive = "1", prop.chisq = F,prop.r = F, prop.c = F, prop.t = F)
tele <- read.csv("tele.csv", stringsAsFactors = TRUE)
# summary(tele)
# str(tele)
# drop useless columns
tele$X <- NULL
tele$duration <- NULL # We only should be using variables that we know before the call
tele$pdaysdummy <- ifelse(tele$pdays == 999, 0, 1) # Changing pdays to a dummy and deleting pdays, 999 means client was not previously contacted
tele$pdays <- NULL
# convert factors to dummy variables (input into ANN has to be numeric)
telemm <- as.data.frame(model.matrix(~.-1, tele))
# telemm
table(telemm$yyes)
# Randomize (done already)
# Normalization
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
tele_norm <- as.data.frame(lapply(telemm, normalize))
str(tele_norm)
set.seed(12345)
kill_rows <- sample(1:nrow(tele_norm), 0.05*nrow(tele_norm))
tele_small <- tele_norm[kill_rows, ]
str(tele_small)
summary(tele_small)
# tele_small is now a small but clean data set for futher analyse
set.seed(12345)
test_set <- sample(1:nrow(tele_small), 0.2*nrow(tele_small))
tele_train <- tele_small[-test_set, ]
tele_test <- tele_small[test_set, ]
# upsample to balance the sample size for 0 and 1 values for yyes for train data
# set.seed(12345)
# library(groupdata2)
# tele_train <- upsample(tele_train, cat_col = "yyes")
# table(tele_train$yyes)
str(tele_train)
summary(tele_train)
# str(tele_test)
# summary(tele_test)
# table(tele_train$yyes)
table(is.na(tele_small))
log_model <- glm(yyes ~., data = tele_train, family = "binomial")
log_pred <- predict(log_model, tele_test, type="response")
log_pred_binary <- ifelse(log_pred >= 0.5, 1, 0)
library(caret)
confusionMatrix(as.factor(log_pred_binary), as.factor(tele_test$yyes), positive = "1")
# label and data split
KNN_train_label <- tele_train[ , 53]
KNN_train <- tele_train[ , -53]
KNN_test_label <- tele_test[ , 53]
KNN_test <- tele_test[ , -53]
# model
library(class)
knn_pred <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 40) # train data rows square root = k
summary(knn_pred)
# evaluation
library(caret)
confusionMatrix(as.factor(knn_pred), as.factor(KNN_test_label), positive = "1")
library(neuralnet)
ann_model <- neuralnet(yyes ~., data = tele_train)
plot(ann_model)
ann_pred <- predict(ann_model, tele_test, type="response")
ann_pred_binary <- ifelse(ann_pred >= 0.5, 1, 0)
confusionMatrix(as.factor(ann_pred_binary), as.factor(tele_test$yyes), positive = "1")
# we need non-binary values for stack model for ANN and logi
library(C50)
DT_model <- C5.0(as.factor(yyes) ~., data = tele_train) # C5.0 models require a factor outcome
# plot(DT_model)
# summary(DT_model)
DT_pred <- predict(DT_model, tele_test)
confusionMatrix(as.factor(DT_pred), as.factor(tele_test$yyes), positive = "1")
library(randomForest)
rf_model <- randomForest(as.factor(yyes) ~., data = tele_train)
plot(rf_model)
rf_pred <- predict(rf_model, tele_test)
confusionMatrix(as.factor(rf_pred), as.factor(tele_test$yyes), positive = "1")
# find patterns
randomForest::importance(rf_model)
randomForest::varImpPlot(rf_model)
# when k=54, Accuracy=0.708
knn_pred_1 <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 41)
#knn_pred_2 <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 58)
confusionMatrix(as.factor(knn_pred_1), as.factor(KNN_test_label), positive = "1")
#confusionMatrix(as.factor(knn_pred_2), as.factor(KNN_test_label), positive = "1")
# when k=40, Accuracy=0.91
knn_pred_1 <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 50)
#knn_pred_2 <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 58)
confusionMatrix(as.factor(knn_pred_1), as.factor(KNN_test_label), positive = "1")
#confusionMatrix(as.factor(knn_pred_2), as.factor(KNN_test_label), positive = "1")
# when k=40, Accuracy=0.91
knn_pred_1 <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 60)
#knn_pred_2 <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 58)
confusionMatrix(as.factor(knn_pred_1), as.factor(KNN_test_label), positive = "1")
#confusionMatrix(as.factor(knn_pred_2), as.factor(KNN_test_label), positive = "1")
# when k=40, Accuracy=0.91
knn_pred_1 <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 100)
#knn_pred_2 <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 58)
confusionMatrix(as.factor(knn_pred_1), as.factor(KNN_test_label), positive = "1")
#confusionMatrix(as.factor(knn_pred_2), as.factor(KNN_test_label), positive = "1")
# when k=40, Accuracy=0.91
knn_pred_1 <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 200)
#knn_pred_2 <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 58)
confusionMatrix(as.factor(knn_pred_1), as.factor(KNN_test_label), positive = "1")
#confusionMatrix(as.factor(knn_pred_2), as.factor(KNN_test_label), positive = "1")
# when k=40, Accuracy=0.91
knn_pred_1 <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 30)
#knn_pred_2 <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 58)
confusionMatrix(as.factor(knn_pred_1), as.factor(KNN_test_label), positive = "1")
#confusionMatrix(as.factor(knn_pred_2), as.factor(KNN_test_label), positive = "1")
# when k=40, Accuracy=0.91
knn_pred_1 <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 20)
#knn_pred_2 <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 58)
confusionMatrix(as.factor(knn_pred_1), as.factor(KNN_test_label), positive = "1")
#confusionMatrix(as.factor(knn_pred_2), as.factor(KNN_test_label), positive = "1")
# when k=40, Accuracy=0.91
knn_pred_1 <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 10)
#knn_pred_2 <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 58)
confusionMatrix(as.factor(knn_pred_1), as.factor(KNN_test_label), positive = "1")
#confusionMatrix(as.factor(knn_pred_2), as.factor(KNN_test_label), positive = "1")
# when k=40, Accuracy=0.91
knn_pred_1 <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 3)
#knn_pred_2 <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 58)
confusionMatrix(as.factor(knn_pred_1), as.factor(KNN_test_label), positive = "1")
#confusionMatrix(as.factor(knn_pred_2), as.factor(KNN_test_label), positive = "1")
# when k=40, Accuracy=0.91
knn_pred_1 <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 5)
#knn_pred_2 <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 58)
confusionMatrix(as.factor(knn_pred_1), as.factor(KNN_test_label), positive = "1")
#confusionMatrix(as.factor(knn_pred_2), as.factor(KNN_test_label), positive = "1")
# when k=40, Accuracy=0.91
knn_pred_1 <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 7)
#knn_pred_2 <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 58)
confusionMatrix(as.factor(knn_pred_1), as.factor(KNN_test_label), positive = "1")
#confusionMatrix(as.factor(knn_pred_2), as.factor(KNN_test_label), positive = "1")
# when k=40, Accuracy=0.91
knn_pred_1 <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 10)
#knn_pred_2 <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 58)
confusionMatrix(as.factor(knn_pred_1), as.factor(KNN_test_label), positive = "1")
#confusionMatrix(as.factor(knn_pred_2), as.factor(KNN_test_label), positive = "1")
# when k=40, Accuracy=0.91
knn_pred_1 <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 13)
#knn_pred_2 <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 58)
confusionMatrix(as.factor(knn_pred_1), as.factor(KNN_test_label), positive = "1")
#confusionMatrix(as.factor(knn_pred_2), as.factor(KNN_test_label), positive = "1")
# when k=40, Accuracy=0.91
knn_pred_1 <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 15)
#knn_pred_2 <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 58)
confusionMatrix(as.factor(knn_pred_1), as.factor(KNN_test_label), positive = "1")
#confusionMatrix(as.factor(knn_pred_2), as.factor(KNN_test_label), positive = "1")
# when k=40, Accuracy=0.91
knn_pred_1 <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 20)
#knn_pred_2 <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 58)
confusionMatrix(as.factor(knn_pred_1), as.factor(KNN_test_label), positive = "1")
#confusionMatrix(as.factor(knn_pred_2), as.factor(KNN_test_label), positive = "1")
# when k=40, Accuracy=0.91
knn_pred_1 <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 25)
#knn_pred_2 <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 58)
confusionMatrix(as.factor(knn_pred_1), as.factor(KNN_test_label), positive = "1")
#confusionMatrix(as.factor(knn_pred_2), as.factor(KNN_test_label), positive = "1")
# when k=40, Accuracy=0.91
knn_pred_1 <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 30)
#knn_pred_2 <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 58)
confusionMatrix(as.factor(knn_pred_1), as.factor(KNN_test_label), positive = "1")
#confusionMatrix(as.factor(knn_pred_2), as.factor(KNN_test_label), positive = "1")
# when k=40, Accuracy=0.91
knn_pred_1 <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 35)
#knn_pred_2 <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 58)
confusionMatrix(as.factor(knn_pred_1), as.factor(KNN_test_label), positive = "1")
#confusionMatrix(as.factor(knn_pred_2), as.factor(KNN_test_label), positive = "1")
# when k=40, Accuracy=0.91
knn_pred_1 <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 37)
#knn_pred_2 <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 58)
confusionMatrix(as.factor(knn_pred_1), as.factor(KNN_test_label), positive = "1")
#confusionMatrix(as.factor(knn_pred_2), as.factor(KNN_test_label), positive = "1")
# when k=40, Accuracy=0.91
knn_pred_1 <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 37)
#knn_pred_2 <- knn(train = KNN_train, test = KNN_test, cl = KNN_train_label, k = 58)
confusionMatrix(as.factor(knn_pred_1), as.factor(KNN_test_label), positive = "1")
#confusionMatrix(as.factor(knn_pred_2), as.factor(KNN_test_label), positive = "1")
# automated parameter tuning of C5.0 decision tree
DT_tune_model <- train(as.factor(yyes) ~., data = tele_train, method = "C5.0")
DT_tune_model
# apply the best C5.0 candidate model to make predictions
DT_tune_pred <- predict(DT_tune_model, tele_test)
confusionMatrix(as.factor(DT_tune_pred), as.factor(tele_test$yyes), positive = "1")
# customized
grid_c50 <- expand.grid(.model = "tree",
.trials = c(10, 20, 30, 40),
.winnow = "FALSE")
ctrl <- trainControl(method = "cv", number = 10,
selectionFunction = "oneSE")
# auto-tune model
DT_tune_model_customized <- train(as.factor(yyes) ~., data = tele_train, method = "C5.0",
metric = "Kappa", trControl = ctrl,
tuneGrid = grid_c50)
DT_tune_customized_pred <- predict(DT_tune_model_customized, tele_test)
# evaluation
confusionMatrix(as.factor(DT_tune_customized_pred), as.factor(tele_test$yyes), positive = "1")
stack_model <- data.frame(log_pred, knn_pred_1, ann_pred, DT_tune_pred, rf_pred, tele_test$yyes)
colnames(stack_model) <- c("logi_reg", "tuned_KNN", "ANN", "tuned_DT", "Random Forest", "True_yyes")
summary(stack_model)
str(stack_model)
set.seed(12345)
test_set <- sample(1:nrow(stack_model), 0.3*nrow(stack_model))
stack_model_train <- stack_model[-test_set, ]
stack_model_test <- stack_model[test_set, ]
str(stack_model_train)
# model
stack_model_DT <- C5.0(as.factor(True_yyes)~., stack_model_train)
stack_model_pred <- predict(stack_model_DT, stack_model_test)
confusionMatrix(stack_model_pred, as.factor(stack_model_test$True_yyes), positive = "1")
set.seed(12345)
test_set <- sample(1:nrow(stack_model), 0.3*nrow(stack_model))
stack_model_train <- stack_model[-test_set, ]
stack_model_test <- stack_model[test_set, ]
str(stack_model_train)
# model
stack_model_DT <- C5.0(as.factor(True_yyes)~., stack_model_train)
stack_model_pred <- predict(stack_model_DT, stack_model_test)
confusionMatrix(stack_model_pred, as.factor(stack_model_test$True_yyes), positive = "1")
library(gmodels)
CrossTable(stack_model_pred, as.factor(stack_model_test$True_yyes), positive = "1", prop.chisq = F,prop.r = F, prop.c = F, prop.t = F)
library(gmodels)
CrossTable(stack_model_pred, as.factor(stack_model_test$True_yyes), positive = "1", prop.chisq = F,prop.r = F, prop.c = F, prop.t = F)
library(gmodels)
CrossTable(stack_model_pred, as.factor(stack_model_test$True_yyes), prop.chisq = F,prop.r = F, prop.c = F, prop.t = F)
set.seed(12345)
test_set <- sample(1:nrow(stack_model), 0.2*nrow(stack_model))
stack_model_train <- stack_model[-test_set, ]
stack_model_test <- stack_model[test_set, ]
str(stack_model_train)
# model
stack_model_DT <- C5.0(as.factor(True_yyes)~., stack_model_train)
stack_model_pred <- predict(stack_model_DT, stack_model_test)
confusionMatrix(stack_model_pred, as.factor(stack_model_test$True_yyes), positive = "1")
library(gmodels)
CrossTable(stack_model_pred, as.factor(stack_model_test$True_yyes), prop.chisq = F,prop.r = F, prop.c = F, prop.t = F)
knitr::opts_chunk$set(echo = TRUE)
#Downloading and Prepping the Data
tele <- read.csv("tele.csv", stringsAsFactors = TRUE)
summary(tele)
#We are deleting the "duration" variable because it is an after the fact measurement. We only should be using variables that we know before the call
tele$duration <- NULL
# Deleting the columns X
tele$X <- NULL
# only for class exercise!
# tele$day_of_week <- NULL
# tele$month <- NULL
# tele$job <- NULL
# tele$education <- NULL
tele$default <- NULL
# Changing pdays to a dummy and deleting pdays
tele$pdaysdummy <- ifelse(tele$pdays == 999, 0, 1)
tele$pdays <- NULL
set.seed(12345)
kill_rows <- sample(1:nrow(tele), 0.05*nrow(tele))
tele <- tele[kill_rows, ]
str(tele)
# Using model.matrix to convert all the factors to dummy variables
# We are converting all of the factors into dummy variables as the input into ANN has to be numeric
telemm <- as.data.frame(model.matrix(~.-1,tele))
table(telemm$yyes)
# Randomize the rows in the data (shuffling the rows)
set.seed(12345)
# tele_random <- telemm[sample(nrow(telemm)),]
telemm <- na.omit(telemm)
table(telemm$yyes)
#Normalize the data
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
# we are going to normalize everything
# we use telemm here because  we did not randomize
tele_norm <- as.data.frame(lapply(telemm, normalize))
str(tele_norm)
# Selects 10000 random rows for test data
set.seed(12345)
# dropeducationilliterate because of NA after norm
tele_norm$educationilliterate <- NULL
# choose 2000 only for class exercise, or 10000
test_set <- sample(1:nrow(tele_norm), 400)
# Depending on R-version and computer, different rows may be selected.
# If that happens, results are different.
# Create a train set and test set
#First the predictors - all columns except the yyes column
tele_train <- tele_norm[-test_set, ]
tele_test <- tele_norm[test_set, ]
# do upsample to balance the sample size for 0 and 1 values for yyes fot train dataset
library(groupdata2)
tele_train <- upsample(tele_train, cat_col = "yyes")
table(tele_train$yyes)
table(tele_test$yyes)
str(tele_train)
summary(tele_train)
# str(tele_test)
# summary(tele_test)
table(is.na(tele_train))
library(neuralnet)
model_1 <- neuralnet(yyes ~., data=tele_train, stepmax = 1e8)
plot(model_1)
model_2 <- neuralnet(yyes ~., data=tele_train, hidden=5, stepmax = 1e8)
plot(model_2)
# model_3 <- neuralnet(yyes ~., data=tele_train, hidden = c(4,3,2), stepmax = 1e8)
#
# plot(model_3)
p1 <- predict(model_1, tele_test) # predict only use the x data from test set, to predict y
summary(p1)
p1_binary <- ifelse(p1 >= 0.5, 1, 0)
p2 <- predict(model_2, tele_test) # predict only use the x data from test set, to predict y
summary(p2)
p2_binary <- ifelse(p2 >= 0.5, 1, 0)
# p3 <- predict(model_3, tele_test) # predict only use the x data from test set, to predict y
# summary(p3)
#
# p3_binary <- ifelse(p3 >= 0.5, 1, 0)
library(gmodels)
CrossTable(p1_binary, tele_test$yyes, prop.chisq = F,prop.r = F, prop.c = F, prop.t = F)
# compare y and true y
library(caret)
#Confusion Matrix
confusionMatrix(as.factor(tele_test$yyes), as.factor(p1_binary), positive = "1")
CrossTable(p2_binary, tele_test$yyes, prop.chisq = F,prop.r = F, prop.c = F, prop.t = F)
confusionMatrix(as.factor(tele_test$yyes), as.factor(p2_binary), positive = "1")
# CrossTable(p3_binary, tele_test$yyes, prop.chisq = F,prop.r = F, prop.c = F, prop.t = F)
# confusionMatrix(as.factor(tele_test$yyes), as.factor(p3_binary), positive = "1")
